{
    # the default template to use for generating actual configuration files    
    "channel_structure_profile": "input_kafka_processing",
    
    # the three mandatory tenant related properties
    "tenant": "mytenant",
    "channel": "sourcefire",
    "vendor": "sourcefire",

    # define channel runtime type
    "channel_type": "storm",
    "cluster_name": "local",
    
    # where the data comes from
    "input": {
        "port": 9902,
        "host": "localhost"
    },

    # the processings you want to run on the data stream
    "processing": {
        "workers": 1,
        "executors": 1,
        "punchlets": [
            { "punchlet": "punchlets/common/input.punch"}, 
            { "punchlet": "punchlets/common/parsing_syslog_header.punch"}, 
            { "punchlet": "punchlets/sourcefire/parsing.punch"}, 
            { "punchlet": "punchlets/common/geoip.punch"}
        ]
    },

    # where the resulting data goes
    "output" : {
        "elasticsearch": {
            "cluster": "es_search",
            "executors" : 1
        }
    },

    # some important runtime settings
    "runtime_settings" : {
        "childopts": "-server -Xms1g -Xmx4g"
    },

    # where the monitoring real time metrics should go
    "metrics": {
        "type": "elasticsearch",
        "settings": {
            "cluster" : "es_search"
        }
    }
}