# Prerequisite

-   A quick look of our API documentation: `https://doc.punchplatform.com/doc/punchplatform-pyspark/html/index.html`
-   Brainstorm your use-case with our existing nodes: `https://doc.punchplatform.com/Reference_Guide/Data_Analytics/Nodes/Elastic_Input.html`
-   A 6.1+ punchplatform release
-   $PUNCHPLATFORM_INSTALL_DIR must be defined

# Notes

A `Makefile` is put at your disposal, use it to clean, lint and format your custom node code !

```sh
# check lint and code formatting for module algorithms
# in general; you should launch this command before any commit
make inspect path=nodes/

# clean unwanted .pyc if any or other python related binaries during runtime execution
make clean
```

**Note 1**

If you are using an IDE like Pycharm (or similar); configure your IDE to use the generated `.venv` from this directory.

**Note 2**

- We expect that on your platform python is a symlink to python3.6.x
- We highly advice you to use some python manager like `pyenv` for development phase !
- In case you want to use shiva for launching pyspark punchlines; make sure that python3.6 is installed (not pyenv).

**Note 3**

A template hierarchy for setuptools to work out of the box is provided; you are free to change it so as to meet your requirements; just keep in mind that it should follows PEP convention for PEX packaging to work !

**Note 4**

For now, you should put your custom python modules in package name *nodes*, like in this example.
This will enable our kibana plugin to display your custom node in **Punchline Editor**.

# Quick Start

Template hierarchy:

```sh
├── full_job.punchline
├── Makefile
├── nodes
│   ├── __init__.py
│   └── my_use_case
│       ├── __init__.py
│       └── my_node
│           ├── complex_algorithm.py
│           └── __init__.py
├── README.md
└── setup.py
```

## Step one

```sh
# get all available commands
make

# info
punchpkg pyspark info

# result
{
    "pyspark_internal_lib_dir": "/home/jonathan/Desktop/standalone/punch-standalone-6.2.0-SNAPSHOT-linux/external/punch-binaries-6.2.0-SNAPSHOT/lib/pyspark",
    "$PUNCHPLATFORM_INSTALL_DIR/lib/pyspark": "internal jars/pexs used by pyspark module",
    "$PUNCHPLATFORM_INSTALL_DIR/extlib/pyspark": "external jars/pexs to be added to punchline runtime as dependencies"
}
```

## Step two (Packaging)

An example node is given in `nodes` package which contains `my_use_case` module with a sub-module `my_node`

```sh
# IMPORTANT
# Terminal should be at the same location as this README.md
ROOT=$(pwd)

# after coding your node
make inspect path=nodes/

# build a pex distribution
punchpkg pyspark package-pex complex_algorithm_dependencies

# pex archive is generated by default in
$ROOT/dist
```

## Step three (Installation)

```sh
punchpkg pyspark install $ROOT/dist/complex_algorithm_dependencies.pex

# check
punchpkg pyspark list-dependencies
```

## Step four (Execute to test)

```sh
punchlinectl start -p full_job.punchline -r pyspark
```
