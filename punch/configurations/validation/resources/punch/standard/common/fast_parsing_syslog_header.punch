{
  // Add to the Json parsed_document going through some informations about the parsing step.
  // Doing this here is questionable, you could do it in every punchlet but then you will generate
  // lots of information that will take room on ElasticSearch disks.
  Tuple raw_document = [logs][raw_log];
  if (raw_document.isEmpty()) {
    throw new PunchRuntimeException("expect to receive the input log under [logs][raw_log]");
  }
  // This will throw a PunchRuntime exception in case the message field does not exists or is not a string
  String message = raw_document.asString();

  Tuple parsedDocument = [logs][log]; // The result document

  parsedDocument:[lmc][parse][ts] = date("iso").get();
  parsedDocument:[lmc][parse][host][name] = getHostName();
  parsedDocument:[lmc][parse][host][ip] = getHostIp();

  if (!syslogHeader().on(raw_document).into(parsedDocument, root:[logs][data])) {
    throw new PunchRuntimeException("parsing error : not a recognized \"timestamp (<facility>) host\" syslog header");
  }
  parsedDocument:[obs][host][name] = parsedDocument:[rep][host][name];
  parsedDocument:[obs][host][ip]   = parsedDocument:[rep][host][ip];
}
